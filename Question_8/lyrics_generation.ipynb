{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hemanths03/CS6910_Assignment_3/blob/main/Question_8/lyrics_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbDyLeTlUtzF",
        "outputId": "7e08a259-aca7-4ca8-80dc-024199fc4c08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuJmHpOPVMFV",
        "outputId": "6e0c6fd8-7d0b-4797-f5c7-da3547ffe199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  eval_tmp.txt  res_tmp.txt  sample_data  train_tmp.txt  train.txt\n"
          ]
        }
      ],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing directory"
      ],
      "metadata": {
        "id": "x4ZEHKzwqflg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPeIG62eVY_N",
        "outputId": "fdbdb8c2-2fc0-4573-85b0-6a4212fb253f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/lyrics\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/lyrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cloning hugging face repository into the drive in above changed path"
      ],
      "metadata": {
        "id": "CLcojz5pq29D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gmd1IX-VrHG",
        "outputId": "e0a01916-ee12-4925-f99b-e221c57d99b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Again changing path"
      ],
      "metadata": {
        "id": "LF3ck9hpq_4e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLViOtOFWTBA",
        "outputId": "8975a26c-89ca-4901-d5c9-21e4cca7f971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/lyrics/transformers/examples/tensorflow/language-modeling\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/lyrics/transformers/examples/tensorflow/language-modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aqu84kK0WdFW",
        "outputId": "8419f057-a24d-4cca-d9ca-f77e6f678431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md  requirements.txt  run_clm.py  run_mlm.py\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuJl7wLmWfaT",
        "outputId": "3397759b-c397-4510-a793-fdc3afa847c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (7.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyarrow --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installing all the requirements required to run cloned repository"
      ],
      "metadata": {
        "id": "DDkg_0iqrr4W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TtMrgzKWxFK",
        "outputId": "d5c0e300-f6f1-4b98-fb9e-e4d64327a398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.1.96)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 1)) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 1)) (1.3.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 1)) (3.8.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 1)) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 1)) (4.64.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 1)) (0.70.12.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 1)) (7.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 1)) (2022.3.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 1)) (0.3.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.8.0->-r requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.8.0->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.8.0->-r requirements.txt (line 1)) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets>=1.8.0->-r requirements.txt (line 1)) (3.0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 1)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 1)) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 1)) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 1)) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 1)) (1.7.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 1)) (2.0.12)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 1)) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets>=1.8.0->-r requirements.txt (line 1)) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 1)) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets>=1.8.0->-r requirements.txt (line 1)) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Appending start and end tags after splitting into test and validation set"
      ],
      "metadata": {
        "id": "jPzjsP_Lr8yw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZEzq36pWx7E",
        "outputId": "882f4092-471e-4c17-f11e-128fa5a67581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training size:5572\n",
            "Evaluation size: 620\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "path = '/content/train.txt'\n",
        "\n",
        "with open(path, 'r') as data:\n",
        "  dataset = [\"<|title|>\" + x.strip() for x in data.readlines()]\n",
        "train, eval = train_test_split(dataset, train_size=0.9, random_state=2020)#seperating out validation data\n",
        "print(\"training size:\" + str(len(train)))\n",
        "print(\"Evaluation size: \" + str(len(eval)))\n",
        "\n",
        "#append the <|title|> token to the input then rejoin with <|endoftext|> and write back out to their respective file.\n",
        "\n",
        "with open('/content/train_tmp.txt', 'w') as file_handle:\n",
        "  file_handle.write(\"<|endoftext|>\".join(train))\n",
        "\n",
        "with open('/content/eval_tmp.txt', 'w') as file_handle:\n",
        "  file_handle.write(\"<|endoftext|>\".join(eval))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CUKCbzaXXc1",
        "outputId": "a87a7e98-9e91-4866-c956-dc8d70d4dd21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers/\n",
            "  Cloning https://github.com/huggingface/transformers/ to /tmp/pip-req-build-enq3z9fz\n",
            "  Running command git clone -q https://github.com/huggingface/transformers/ /tmp/pip-req-build-enq3z9fz\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.64.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (0.0.49)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (0.5.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.11.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0.dev0) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.0.dev0) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.19.0.dev0) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/huggingface/transformers/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For fine tuning GPT-2 we will be using Huggingface and will use the provided script run_clm.py"
      ],
      "metadata": {
        "id": "p-xymf30txsN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxb7oALxXPGM",
        "outputId": "e84d8653-59ec-40e7-943a-1930b51e4b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using custom data configuration default-8791943a31354c42\n",
            "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-8791943a31354c42/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n",
            "\rDownloading data files:   0% 0/2 [00:00<?, ?it/s]\rDownloading data files: 100% 2/2 [00:00<00:00, 8338.58it/s]\n",
            "\rExtracting data files:   0% 0/2 [00:00<?, ?it/s]\rExtracting data files: 100% 2/2 [00:00<00:00, 647.92it/s]\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-8791943a31354c42/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n",
            "\r  0% 0/2 [00:00<?, ?it/s]\r100% 2/2 [00:00<00:00, 1074.09it/s]\n",
            "loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"distilgpt2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.19.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"distilgpt2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.19.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/distilgpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/55051ac97dcc32f0a736d21a32a4d42b0d9b90f117ca7c38e65038b04bd5c3f5.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "loading file https://huggingface.co/distilgpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/9dfb299b74cdf7601ba7cd3a8073dbdac351caec0ed7ab5849b098b3c8ae3d57.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/distilgpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/accb287b5a5396b2597382916b6cc939fdab1366e89475a92338d3971b3d02b7.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "loading file https://huggingface.co/distilgpt2/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/distilgpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/distilgpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"distilgpt2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.19.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "Running tokenizer on dataset: 100% 6/6 [00:00<00:00, 33.59ba/s]\n",
            "Running tokenizer on dataset: 100% 1/1 [00:00<00:00, 54.75ba/s]\n",
            "Grouping texts in chunks of 1024: 100% 6/6 [00:00<00:00, 72.46ba/s]\n",
            "Grouping texts in chunks of 1024: 100% 1/1 [00:00<00:00, 102.92ba/s]\n",
            "Tensorflow: setting up strategy\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/mixed_precision/loss_scale.py:52: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n",
            "2022-05-02 09:59:24.559216: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "loading weights file /content/res_tmp.txt/tf_model.h5\n",
            "2022-05-02 09:59:24.857558: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /content/res_tmp.txt.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
            "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
            "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
            "\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 3.0762Configuration saved in /content/res_tmp.txt/config.json\n",
            "2022-05-02 09:59:44.468845: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154389504 exceeds 10% of free system memory.\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 19s 1s/step - loss: 3.0762\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 3.0391Configuration saved in /content/res_tmp.txt/config.json\n",
            "2022-05-02 09:59:52.092700: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154389504 exceeds 10% of free system memory.\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.0391\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 3.0134Configuration saved in /content/res_tmp.txt/config.json\n",
            "2022-05-02 09:59:59.717714: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154389504 exceeds 10% of free system memory.\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.0134\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.9799Configuration saved in /content/res_tmp.txt/config.json\n",
            "2022-05-02 10:00:07.373234: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154389504 exceeds 10% of free system memory.\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.9799\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.9481Configuration saved in /content/res_tmp.txt/config.json\n",
            "2022-05-02 10:00:15.062151: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154389504 exceeds 10% of free system memory.\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.9481\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.9302Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.9302\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.8979Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.8979\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.8761Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.8761\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.8457Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.8457\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.8200Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.8200\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.7843Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.7843\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.7642Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.7642\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.7402Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.7402\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.7252Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.7252\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.6922Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.6922\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.6727Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.6727\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.6476Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.6476\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.6328Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.6328\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.6049Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.6049\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.5871Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.5871\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.5572Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.5572\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.5416Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.5416\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.5103Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 9s 1s/step - loss: 2.5103\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.4841Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.4841\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.4777Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.4777\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.4478Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.4478\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.4364Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.4364\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.4110Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.4110\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.4026Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.4026\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.3700Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.3700\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.3552Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.3552\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.3225Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.3225\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.3075Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.3075\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.3036Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.3036\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.2818Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.2818\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.2626Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.2626\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.2453Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.2453\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.2221Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.2221\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.2157Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.2157\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.1917Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.1917\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.1878Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.1878\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.1722Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.1722\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.1476Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.1476\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.1381Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.1381\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.1295Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.1295\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.1119Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.1119\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.0915Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.0915\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.0765Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.0765\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.0692Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.0692\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.0474Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.0474\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.0388Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.0388\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.0354Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 9s 1s/step - loss: 2.0354\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.0193Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.0193\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.0092Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.0092\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.9943Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9943\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.9759Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9759\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.9714Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9714\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.9534Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9534\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.9506Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 9s 1s/step - loss: 1.9506\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.9315Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9315\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.9276Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9276\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.9182Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9182\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.9004Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9004\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.9072Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9072\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8853Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8853\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8806Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8806\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8730Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8730\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8610Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8610\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8555Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8555\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8479Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8479\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8468Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8468\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8304Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8304\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8267Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8267\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8107Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8107\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8087Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8087\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8066Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8066\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7935Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7935\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7888Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7888\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7826Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7826\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7779Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7779\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7775Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7775\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7681Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 9s 1s/step - loss: 1.7681\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7687Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7687\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7566Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7566\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7585Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7585\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7553Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7553\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7504Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7504\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7586Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7586\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7447Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7447\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7468Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 9s 1s/step - loss: 1.7468\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7287Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7287\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7444Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7444\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7282Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7282\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7326Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7326\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7250Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7250\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7295Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7295\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7301Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7301\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7285Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7285\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7253Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7253\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7193Configuration saved in /content/res_tmp.txt/config.json\n",
            "Model weights saved in /content/res_tmp.txt/tf_model.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7193\n",
            "Traceback (most recent call last):\n",
            "  File \"run_clm.py\", line 528, in <module>\n",
            "    main()\n",
            "  File \"run_clm.py\", line 510, in main\n",
            "    validation_perplexity = math.exp(history.history[\"val_loss\"][-1])\n",
            "KeyError: 'val_loss'\n"
          ]
        }
      ],
      "source": [
        "!python run_clm.py \\\n",
        "--model_type gpt2-small \\\n",
        "--model_name_or_path distilgpt2 \\\n",
        "--train_file /content/train_tmp.txt \\\n",
        "--do_train \\\n",
        "--validation_file /content/eval_tmp.txt \\\n",
        "--do_predict \\\n",
        "--per_gpu_train_batch_size 128 \\\n",
        "--save_steps -1 \\\n",
        "--num_train_epochs 100 \\\n",
        "--fp16 \\\n",
        "--output_dir=/content/res_tmp.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufWJdlN9dOlC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z6MHqKGdPYr",
        "outputId": "c21ed344-134f-4e76-d2ae-7682e37cb1fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /content/res_tmp.txt/tf_model.h5.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# setup imports to use the model\n",
        "from transformers import TFGPT2LMHeadModel\n",
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "#using the pre-trained GPT-2 tokenizer for creating our input sequence to the model.\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = TFGPT2LMHeadModel.from_pretrained(config='/content/res_tmp.txt/config.json',pretrained_model_name_or_path='/content/res_tmp.txt/tf_model.h5',)\n",
        "\n",
        "input_ids = tokenizer.encode(\"I love Deep Learning\", return_tensors='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generating lyrics"
      ],
      "metadata": {
        "id": "a_QH-iRbuR7V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCHUeNy8gO5u",
        "outputId": "5c23e610-014b-4aac-affc-9e6e28fe4205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: I love Deep Learning\n",
            "\tWord count for thats how deep I am at it CONSULTIVE enough to let you know in a few seconds What if somebody wasnt CEO baby look back on their resume Did he mention that his years of experience with Motown sucked him dry consoling me got my head cold How could she not live her dream Get emotional Dont give up Plan B Yes No Imma ever say YES Thats what dreams come true Do something when your heart is racing errrr TIME Outta the box The planks In this crazy hour Jump out into action Snatch some crabs Pull off lights Trullize roof Shoppe There goes another realm where niggas cant control themselves Tone It down like an Altoids toothpick Tip Her nose straightin Go deeper than Caprices Excuse ME though Its Maybach Porsche Like candy cane Absolute right here we stand Anakin piece Digital Underground Source Of Power Pssh We all grown used just about anything Media outlets trying new things Report abuse Golly more Ease welcome Home Ye are You Knew Yeezy were real life fake Turn around report card Ill piss twice OJ Jackson passed away Vibe Ten notes and two Twista Shorty Thank God For Love vie through eternity Chitown Southside Drive Past Slick Rick Rossinger Centipede Welcome to American Idol A word chosen When did Napoleon endear Me Too late Katrina hit them Alligator Rented Weeks Preachers teach us Jesus no Apologies Emmanuel Macron Tell em hate never forget Left hiphop legend Fresh from college Snapchat Hova McLovr Loyola Mary Kate Moss Margiela Body language Brazilian Romance Express Yourself Asking Us Could Young Ones Cody Chesnut Alexander Wang Life expectancy Limon Registration period Cesar Chavez said He wants rich girls only so long as they save face Def Jam Yo Old Spice Boys style Nas already established Boundaries Tribe Called Quest Common Basecamp Keisha Knight Longo Austin Scott City Limits free will Takeover Park see below Uptime Uhmm maybe Kaymin Maybe Not This shit man Can people talk without makeup Farrakhan Alexis Ohanian Kanye West Beyonce Yeah yeah yes Yep uhuh now yall can make these hoes be anywhere but ooh ok Okay okay Now go ahead And get dramatic panics Lets call bullshit then do CPR Will probably undress prior to conception Marni Whitney Houston See also shooting stars Aurora Borealis Traceys bitches Bridget Peep Jigga Versace Pretty much everything Almost everybody Who knew Charles Manson made hundreds or even thousands Watch Listeners Say many times Patrons Communicate Hours Sibling rivalry Seasonal Questions Concrete rules Are basic Even Michael Phelps Evidently none should own our sanity Q&A Felt really Hip hop Honestly Whatever else craziness might have impregnated Givenchy Geographic phenomenon Janet Jackman Swartz Quizzes Big Pun Ice Cube Patron Saint Laurent Fridays Workout time Runs well raunchier Equinox Bathrobe Try harder Odell Beckham Estelle Monique Rachel Mustard Face Preschooled Just try different classes Graduation Entourage Emotions begin shifting due both parties Major Leagues Backdrafting Project Runway Phrase code Whipped lyrics On stage Wind chimes in Electra Phantom soundproof Man powerplant Drizzy Osbourne JayZ Force True Lies Minivan Lightspeed Range Rover Suave Homestyle DoubleTreeHood Marshall became one helluva Autobahn Timbuck Norah Bad Dog Lovelight Uncle Sam Pol Potassium Iodine United States Senator Elgin Brown Louie Depends upon Party ID But by myself Damn nobody expected George Fore called ya Hey Mama Donatellus Ugandan Hugos Forever after Grammy nominated Furor Eli Myhales Year Thanksgiving Wife Ellipsand Mimosa Linda Rey Santa Rosa Brendaans birthday present Christ its Sunday afternoon Happy New Years Eve Christmas tree rings Mr Pink Shyne home Remember those bittersweet hours ago Cheers MasterChef Club Captain America Secret Service Ghosts Gospel College Ghost Town Hallucinations www.circleademia dot com Whatsappdaddy DOT NET Neutrality whatsuprightnowcloneembedreportprint music video message board game minglecraft intros fore tonight varicosex dnoddamn dyke xmills baller Block winner Oscars espanolife MTV award readme Award winning actor Russell Crowe Xmas giftestries Phillip Barkley accept ekcd picture book design major leaguiestrod James Harden cosmopolitan Kobe Bryant Huge tits small town swaggy prom queen bee stoled black excellence African dick big city blockades Asian summertime tantrums Arbor Clockwork Something went wrong Blood clot thoughtless Walt Disney World Stacks wit nothing tragic Egyptian god Greek mythology Cosplay fair share of news High Altitude Lake Michigan girl grab bag massage Gucci while holding La Familia Fashion Week exclusive slip zippers Zara Jean Paul Joseph admit ignorance Jacob came aboard first class passengers Titanic Christina Milian Jacobs says sometimes students become selfconscious Sure thing happened last winter Chloe Mitchell comments very mean One Direction hes such a fucking asshole who disrespectSophisticatedThinkingAboutMeToo often managers realize there needsto changes within departmentsPerformerOnePlusOne Plus\n",
            "\n",
            "1: I love Deep Learning\n",
            "\tIf I talk to people that know me best then Imma have a few more turds baby daddy\n",
            "And my credits so bad they even sacked him for it\n",
            "This the number one trophy wife she gave Keyshia Cole man That nigga is legendary Oh yeah we need another session with JayZ This all new exciting when you get used up yo ass Yo style\n",
            "Thats why shortys hollerin where Shorty at Work\n",
            "\u001fWith niggas masked as Michael Jackson wearing winter clothes\n",
            "rawdownloadYou want extra hard work and thats what makes us great parents always try your hardest\n",
            "oreAndOnlineTo whom would Id ever fuck his bitch on TV\n",
            "quickShipWe can make ends meet wherever dreams go before conception What if Mary was in Da Club\n",
            "From Hollywood producers like Russell Crowe\n",
            "\u0012My psychic told her It feel different every time You touch da Vinci Welcome back home\n",
            "But first let em see who made this religion known\n",
            "\u000eTry imagining something entirely imaginary Even though nobody knew about real life\n",
            "\u0014Hahaha Ill move here soon Asics from Ghana realize ham no tomorrow Is magic On those nightmares true Yes sir\n",
            "She said Look how well do girls perform See these numbers just add ups Yeezy never really hit them huh\n",
            "\n",
            "2: I love Deep Learning\n",
            "\tThat we be selfconscious of not knowing what the fuck I been up to lately\n",
            "\u0004If somebody came over for advice and gave me a pound right now maybe that would help us with some errands\n",
            "\u0015A little freaky talk show where people laugh in your face Getting my chain back fixed\n",
            "And every time Im feeling down feel like home after work\n",
            "embedreportprintShe said she just got divorced so they take her by storm\n",
            "\u0001Man Yeezy needn't touch him before bed ooh boy thats crazy huh\n",
            "\n",
            "3: I love Deep Learning\n",
            "\tIm just trying to do the impossible but Im doing well with my token fees How many more times will I get asked for it\n",
            " After all of that you said You are lame and in no time soon Im finally here ya know how crazy this game is\n",
            "You say what people ask me when they hear bout back pain\n",
            "\u001dWe aint accustomed seeing friends on TV looking like Damn got nothing to lose yo\n",
            "My psychic told her Get off your couch now\n",
            "\u0017He keep holdin out girls who might flirt too deep\n",
            "And we dont care at first sight What would happen if she didnt grow breasts again\n",
            "\n",
            "4: I love Deep Learning\n",
            "\tLesson learned lesson I still teach now Im successful How to Do That Right Now\n",
            "\u0002She asked me do the opposite of what she told her people back in December when they knew he was gone\n",
            "rawdownloadIm tired you old Old Spice wearing winter clothes\n",
            "\u0001Uh but its good that we made it here anyway baby boy did ugh\n",
            "\u0007Yeah Mr West is very real Dr King Yes sir some men pray for us Dior Hommeister\n",
            "\u0016With more ladies than them dykes huh\n",
            "Yall got dickas much as Michael Jackson penis\n",
            " aint nobody expect this type ooh where all my niggas get their ass OO Where can these hoes go wrong Ohh hell yeah Heres no denying Xs\n",
            "We make em jerk from South Park with his swag Rick Ross grunt\n",
            " externalToYou know those words just might help clear up your mind\n",
            "But since yah and thats an understatement man ah oh why amaor even agree on one basis\n",
            " TheNitromeSo many wonderful things happened so fast habloating hours later\n",
            "\u0003Shes feeling invisible realize how impure everything feel outside Of The Matrix\n",
            "\u001bWhy every superhero need cameras Shouldn't They try again Could somebody really save our day\n",
            "\u0000And unless God take care OFD Yeahhhhh And then next time Ill roll over Cause tonight night wont come soon Ving Rhames dont lie YES YES No matter who ask ME Can someone truly protect His image\n",
            "\u0018Haters saying Youve been together too long enough Man This song will turn shit around Ye\n",
            "AyeBoned Kim Kardashian Yeezy probably better be live at home Yo We say Kanye has arrived AAAAAHHAYSSARRRrright there KIAUGHAAHHHHay slow down let alone burn blaze okay ok maybe way less damaging\n",
            "\u0006How could anybody predict future events like today's NBA play close to LeBron James\n",
            "\u001dLets exchange angles lets see whats going on right now\n",
            "This year Left field goal percentage drop by nearly three million after halftime\n",
            "Hold hands cause hes strong Its common sense But if anything imitated Just drive off Camry Like Tim Cook\n",
            "\u001fBefore MTV hit titties Turn round robins Common Sense Yep\n",
            "\fWhen werent homie sex always easy boys become extra raunchy dog\n",
            "\u0010Tell him tell yo friends Hey teacher Whats advice instead of preaching It preach truth Jesus walks before everyone Welcome To Zion\n",
            "ActionCodeMake music videos based purely on historical knowledge\n",
            "They cant keep track( Clock apk )\n",
            "My heart doesnt want nothing worse about myself xdare\n",
            "\u001aNow everybody gon have dinner table discussion center stage face\n",
            "\u0014If history makes ya sons daughters Qandro Didier d'Or groom Hov Khizra\n",
            "\u000bPiss On My Face Off Why Life Is Bad Honestly\n",
            "\u000eCause sometimes life gets ugly little dreams are dreamlike hey So please forgive me\n",
            "quickShipDamn Ellipsis Pulled In R Us Baby Cuz When All Poppin Are Huggin Talkant\n",
            "\u0019It took months til November finally came out Uhuh uhumll hear bout another lawsuit Holli not Mary\n",
            "\u0011Baby girl wanna talk because fuck Motherfucker coked dude already closed doors\n",
            "StreamerBotThe entertainment industry whos provoking kids worldwide including Ugg Bosses\n",
            "oreAndOnlineMan Shoutout Out For JayZ Who Laughs OMG Damn Me Too bad Gosh haha\n",
            "\n"
          ]
        }
      ],
      "source": [
        "generated_text_samples = model.generate(\n",
        "    input_ids, \n",
        "    max_length=10000,  \n",
        "    num_return_sequences=5,\n",
        "    no_repeat_ngram_size=2,\n",
        "    repetition_penalty=1.5,\n",
        "    top_p=0.92,\n",
        "    temperature=.85,\n",
        "    do_sample=True,\n",
        "    top_k=125,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "#Print output for each sequence generated above\n",
        "for i, beam in enumerate(generated_text_samples):\n",
        "  print(\"{}: {}\".format(i,tokenizer.decode(beam, skip_special_tokens=True)))\n",
        "  print()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled0 (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}